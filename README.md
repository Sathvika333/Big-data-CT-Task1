*COMPANY* : CODTECH IT SOLUTIONS  
*NAME* : R Sathvika teja 
*INTERN ID* : CT12WVZF 
*DOMAIN* : Data Analytics  
*DURATION* : 12 weeks  
*MENTOR* : Neela Santhosh Kumar 

# Big-data-CT-Task1

Task Description
This task focuses on performing a comprehensive analysis of a bank marketing campaign to evaluate its effectiveness in influencing customer behavior, utilizing PySpark for processing and analytical computations. The dataset used in this analysis comprises various attributes related to client demographics, banking history, and responses to a telemarketing campaign, with the ultimate goal of predicting whether a customer will subscribe to a term deposit.

The primary objective of this task is to derive meaningful insights and patterns from a large volume of structured data, leveraging PySpark's powerful distributed computing capabilities. Given the increasing need for scalable data processing in real-time applications, this task also highlights the practical application of big data tools in solving real-world business problems.

The dataset includes attributes such as age, job type, marital status, education level, default status, housing and personal loan indicators, contact communication type, last contact duration, campaign performance metrics, and economic indicators (like employment variation rate, consumer price index, and interest rate). The target variable is a binary indicator of whether the client has subscribed to a term deposit.

The analysis begins with loading the dataset into a PySpark DataFrame, followed by exploratory data analysis (EDA) to understand the structure, schema, and quality of the data. The dataset is checked for null values, duplicate entries, and other inconsistencies. Appropriate data cleaning steps are performed to ensure that the data is reliable and suitable for further analysis.

Following the EDA, descriptive statistics are computed to analyze the distribution of features and understand customer demographics and behaviors. The analysis further includes grouping and aggregating data based on key attributes such as job type, age group, marital status, and education to identify segments that are more likely to subscribe to the term deposit.

In the next phase, feature engineering techniques are applied to transform categorical variables into numerical formats using methods such as StringIndexer and OneHotEncoder, which are essential for building machine learning models in PySpark. The dataset is then prepared for modeling through a train-test split.

A logistic regression model is employed to predict customer subscription likelihood, and model performance is evaluated using standard classification metrics such as accuracy, precision, recall, and F1-score. The model's interpretability is enhanced through the analysis of feature importance, which helps identify the most influential factors affecting customer decisions.

The entire analysis demonstrates a structured approach to solving a classification problem using big data tools. It not only highlights the utility of PySpark in handling and processing large datasets efficiently but also shows how data-driven insights can support decision-making in banking marketing strategies.

In conclusion, this task emphasizes the significance of big data analytics in the banking sector by showcasing how campaign effectiveness can be assessed through data science. The methodology adopted is scalable, adaptable, and relevant to any organization aiming to optimize marketing efforts through predictive modeling and customer segmentation.


